"use strict";(globalThis.webpackChunkhomanoid_robotics_book=globalThis.webpackChunkhomanoid_robotics_book||[]).push([[9492],{5231:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"reference/glossary","title":"Glossary of Physical AI Terms","description":"A","source":"@site/docs/reference/glossary.md","sourceDirName":"reference","slug":"/reference/glossary","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/reference/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/KashanKamboh/Physical-AI-Humanoid-Robotics-Book.git/edit/main/docs/reference/glossary.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Capstone Execution Guide","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/capstone/guide"},"next":{"title":"Technical Standards Page","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/reference/technical-standards"}}');var o=i(4848),r=i(8453);const t={sidebar_position:1},a="Glossary of Physical AI Terms",l={},c=[{value:"A",id:"a",level:2},{value:"B",id:"b",level:2},{value:"C",id:"c",level:2},{value:"D",id:"d",level:2},{value:"E",id:"e",level:2},{value:"F",id:"f",level:2},{value:"G",id:"g",level:2},{value:"H",id:"h",level:2},{value:"I",id:"i",level:2},{value:"J",id:"j",level:2},{value:"K",id:"k",level:2},{value:"L",id:"l",level:2},{value:"M",id:"m",level:2},{value:"N",id:"n",level:2},{value:"O",id:"o",level:2},{value:"P",id:"p",level:2},{value:"Q",id:"q",level:2},{value:"R",id:"r",level:2},{value:"S",id:"s",level:2},{value:"T",id:"t",level:2},{value:"U",id:"u",level:2},{value:"V",id:"v",level:2},{value:"W",id:"w",level:2},{value:"X, Y, Z",id:"x-y-z",level:2},{value:"Additional Resources",id:"additional-resources",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"glossary-of-physical-ai-terms",children:"Glossary of Physical AI Terms"})}),"\n",(0,o.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Action"}),": A ROS 2 communication pattern for long-running tasks with feedback and goal management."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Affordance"}),": The property of an object that indicates its possible use or function to an agent."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Agent"}),": An autonomous system that perceives its environment and takes actions to achieve goals."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Artificial General Intelligence (AGI)"}),": Hypothetical AI that demonstrates human-level intelligence across diverse domains."]}),"\n",(0,o.jsx)(n.h2,{id:"b",children:"B"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Behavior Tree"}),": A hierarchical structure used for organizing and controlling robot behaviors."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Bounding Box"}),": A rectangular box that encloses an object in 2D or 3D space, used for object detection."]}),"\n",(0,o.jsx)(n.h2,{id:"c",children:"C"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Cartesian Space"}),": The 3D coordinate system used to describe positions and orientations in physical space."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Cognitive Architecture"}),": A framework for organizing and implementing intelligent behaviors in robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Command and Control"}),": The system responsible for interpreting commands and executing robot actions."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Computer Vision"}),": The field of study focused on enabling computers to interpret and understand visual information."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Control Theory"}),": The mathematical study of dynamical systems and their control using feedback."]}),"\n",(0,o.jsx)(n.h2,{id:"d",children:"D"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Deep Learning"}),": A subset of machine learning using neural networks with multiple layers."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Digital Twin"}),": A virtual replica of a physical system used for simulation and analysis."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Dynamics"}),": The study of forces and torques that cause motion in mechanical systems."]}),"\n",(0,o.jsx)(n.h2,{id:"e",children:"E"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Embodied AI"}),": Artificial intelligence that is integrated with physical systems to interact with the world."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"End-Effector"}),": The tool or device at the end of a robotic manipulator used to interact with objects."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Environment"}),": The physical or simulated space in which a robot operates."]}),"\n",(0,o.jsx)(n.h2,{id:"f",children:"F"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Forward Kinematics"}),": The process of calculating the position of a robot's end-effector from joint angles."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Fiducial Marker"}),": A visual marker used for precise object localization and orientation."]}),"\n",(0,o.jsx)(n.h2,{id:"g",children:"G"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gazebo"}),": A physics-based 3D simulation environment for robotics."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Generalization"}),": The ability of a system to perform correctly on new, unseen data or situations."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Geometric Reasoning"}),": The ability to understand and manipulate spatial relationships."]}),"\n",(0,o.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Human-Robot Interaction (HRI)"}),": The study of interactions between humans and robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Humanoid Robot"}),": A robot with human-like form and capabilities."]}),"\n",(0,o.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Inverse Kinematics"}),": The process of calculating joint angles needed to achieve a desired end-effector position."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Isaac Sim"}),": NVIDIA's simulation environment for robotics and AI."]}),"\n",(0,o.jsx)(n.h2,{id:"j",children:"J"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Joint Space"}),": The coordinate system defined by robot joint angles."]}),"\n",(0,o.jsx)(n.h2,{id:"k",children:"K"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Kinematics"}),": The study of motion without considering the forces that cause it."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Knowledge Representation"}),": The field of artificial intelligence focused on representing information about the world."]}),"\n",(0,o.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Language Model"}),": An AI model trained to understand and generate human language."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Latent Space"}),": A compressed representation space used in machine learning models."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"LiDAR"}),": Light Detection and Ranging, a sensing technology using laser light."]}),"\n",(0,o.jsx)(n.h2,{id:"m",children:"M"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Manipulation"}),": The ability of a robot to physically interact with objects in its environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Manipulator"}),": A robotic device designed to manipulate objects."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Mapping"}),": The process of creating a representation of the environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Middleware"}),": Software that provides common services and capabilities to applications."]}),"\n",(0,o.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Navigation"}),": The ability of a robot to move through its environment to reach goals."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Neural Network"}),": A machine learning model inspired by biological neural networks."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Node"}),": A process in ROS that performs computation."]}),"\n",(0,o.jsx)(n.h2,{id:"o",children:"O"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Obstacle Avoidance"}),": The capability to detect and navigate around obstacles."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Occupancy Grid"}),": A 2D representation of environment space as occupied or free."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"OpenCV"}),": An open-source computer vision and machine learning software library."]}),"\n",(0,o.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Perception"}),": The ability to interpret sensory information to understand the environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Physical AI"}),": The integration of artificial intelligence with physical systems and robotics."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Point Cloud"}),": A set of data points in 3D space, typically from 3D sensors."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Pose"}),": The position and orientation of an object in 3D space."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Publisher"}),": A ROS node that sends messages on a topic."]}),"\n",(0,o.jsx)(n.h2,{id:"q",children:"Q"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Quaternion"}),": A mathematical representation for 3D rotations and orientations."]}),"\n",(0,o.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Real-time"}),": Systems that respond to inputs within strict time constraints."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Reinforcement Learning"}),": A type of machine learning where agents learn through interaction with an environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Robot Operating System (ROS)"}),": Flexible framework for writing robot software."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"ROS 2"}),": The second generation of the Robot Operating System with improved architecture."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Rigid Body"}),": An object that maintains its shape and size under forces."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Robotics"}),": The field of technology focused on the design, construction, and operation of robots."]}),"\n",(0,o.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sensor Fusion"}),": The process of combining data from multiple sensors to improve perception."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Service"}),": A ROS communication pattern for request-response interactions."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Simultaneous Localization and Mapping (SLAM)"}),": The computational problem of constructing a map while localizing in it."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Subscriber"}),": A ROS node that receives messages on a topic."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"System Integration"}),": The process of combining different subsystems into a unified system."]}),"\n",(0,o.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Task Planning"}),": The process of determining a sequence of actions to achieve goals."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Teleoperation"}),": Remote operation of a robot by a human operator."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Topic"}),": A ROS communication channel for passing messages between nodes."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Trajectory"}),": A path with timing information for robot motion."]}),"\n",(0,o.jsx)(n.h2,{id:"u",children:"U"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Unity"}),": A real-time 3D development platform used for simulation and visualization."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Unstructured Environment"}),": An environment without predefined organization or constraints."]}),"\n",(0,o.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Vision-Language-Action (VLA)"}),": Systems that integrate visual perception, language understanding, and physical action."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Visual Servoing"}),": Control of robot motion based on visual feedback."]}),"\n",(0,o.jsx)(n.h2,{id:"w",children:"W"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Workspace"}),": The space in which a robot can operate."]}),"\n",(0,o.jsx)(n.h2,{id:"x-y-z",children:"X, Y, Z"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"XYZ"}),": The three-dimensional coordinate system axes (X, Y, Z)."]}),"\n",(0,o.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,o.jsx)(n.p,{children:"For more comprehensive definitions, see:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://docs.ros.org/",children:"ROS Documentation Glossary"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://ras.ieee.org/",children:"IEEE Robotics and Automation Society Standards"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://docs.nvidia.com/isaac/",children:"NVIDIA Isaac Documentation"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>a});var s=i(6540);const o={},r=s.createContext(o);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);